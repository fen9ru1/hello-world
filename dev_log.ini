20231003
    21:30-22:30
        アカウント展開ルール実装検討(共通版から個別版)
            DB展開ルール定義書(アカウント展開ルール(共通版から個別版))

共通版から個別版 検討
    前提
        W/R 使い分けしない
        W/R 使い分ける
        
    条件
        main指標(DB性能)
            要素(パラメータ)
                P_MC：PER_SCHEMA_MAX_CAPACITY
                "x"_cc：per_schema_current_capacity ([製品略語]-cc)
                // 条件 超えて、何回、どれぐらい続いた？

            要素の監視手段
                定期的にperformance insight表示画面(e.g.slice by DB usr)に見に行く
                    like monthy report?
                    //(e.g.slice by DB usr)
                    
                監視の自動化検討？
                    stream to datadog?
                    triger alert like: 製品 abc is overweight than expect

        other指標01(ユーザ数)
            あくまで目安、観察

    共通版から個別版に伴ったデータ移行_1
        前提
            移行先である個別版用のawsアカウントが存在し、アカウントの初期設定完了
            個別版用のルールは構築済み(amazon aurora DB clusterを含む)
            
        データ移行(共通版DBから個別版)手段    
            a.Glue studio 
                clawler
                glue job
            b.Glue DataBrew
                GUI付きツール
            c.共通版Aurora ClusterからS3 export,個別版Aurora ClusterからS3 BuckertをAuroraにimport
                特定のデータベースやスキーマ、テーブルといった単位で一部分だけエクスポートすることも可能
                エクスポートはバックグラウンドで処理されるため、DBクラスターのパフォーマンスに影響しない

      
            e.dms
            //f.clone

    共通版から個別版に伴ったデータ移行_2
        前提
            移行先である個別版用のawsアカウントが存在し、アカウントの初期設定完了
            個別版用のルートは構築済み(amazon aurora DB clusterを含まない)
            
        データ移行(共通版DBから個別版)手段    
            d.snapshot復元
                共通版アカウントのRDSスナップショット(以降cmn-snapshot)を個別版アカウントと共有
                個別版アカウント上、cmn-snapshotでDB clusterを復元 
                個別版DB cluster上、必要としないDB schemaを削除


検証
    優先度
        c&d > a&b
    検証環境、step
        step1. gen-dev(共通DB相当) => datalake-dev(個別DB相当　263086559565)  //テスト
            アプローチc 検証

            アプローチd 検証
                Snapshot Name : cmn-db-like-snapshot  //308GB
                custem-key-4-rds-share-from-gen-dev-2-datalake-dev
                cmn-db-like-snapshot-copy
                info:
                    https://qiita.com/tukapai/items/2b9d44fcb8ef8684578c
        step2. lob-wae(共通DB相当) => gen-dev(共通DB相当) 　　　 //Seeq検証
            アプローチc&d それぞれ検証

        #移行先、はgrp-ser-1優先

10/4 d//------------snapt shot利用して、復元方法　動作確認

    環境
        gen-dev（共通相当）-> lake-dev(個別相当)

    設定memo , lake-dev上
        indifier:
            lob-db-like-lake-dev

        snapshot からrestoreする時
            Availability & durability
                Multi-AZ deployment　最初multi-azで展開できない　
                + reader instance　後から修正する

            snpashotを共有するために
                kms設定必要

            db userとかは引き継ぐ？
                    yes => 不要なuserを消す必要あり
                    adminのpass引き続がれたため、security面変更したよい

            schemaがある？
                yes	
                データ件数もok　//snapshot取得時点までデータは同様である

            Turn on Performance Insights
                on になっていない(もとgen-dev DBの Performance Insightsがoffで試した)
                
            差分は
                どの手段でもある課題	
        
        
    next step
        西尾さんseeq問題、
            lob-wae（共通相当）-> gen-dev(個別相当)
                問題対応用DB環境 : endpoint決まる

            =>c.共通版Aurora ClusterからS3 export, 個別版Aurora ClusterからS3 BuckertをAuroraにimport

        gen-dev
            do -> s3 export 


Export identifier
    rds-export-job-test

S3 name:
    iotpf-dev-s3-aurora-export-to-s3-bucket-350863595295

IAM role name
    iotpf-dev-role-aurora-export-to-s3

IAM police
    iotpf-dev-iampol-aurora-export-to-s3

KMS
    custem-key-4-aurora-export-to-s3-key


ref:
    https://dev.classmethod.jp/articles/aurora-cluster-export-s3/

[Partial] 
    wae_dev_db

time cost:
    starting 15:16~
        =>20min,instance lauch time?
    in-progress 15:33
        =>300GB/30min
    end 16:03 (UTC+09:00)
        


IAM role name
    iotpf-dev-role-aurora-import-from-s3

IAM police
    iotpf-dev-iampol-aurora-import-from-s3

vpc-end point
    iotpf-dev-vpce-apne1-com-s3



info-*table
    dump-> schema
store-table
    //Glue
    //S3_Load

ref インポート記述
    https://aws.amazon.com/jp/blogs/news/best-practices-for-exporting-and-importing-data-from-amazon-aurora-mysql-to-amazon-s3/


{
            "Action": [
                "kms:Decrypt",
                "kms:Encrypt",
                "kms:GenerateDataKey",
                "kms:DescribeKey",
                "kms:ReEncrypt*"
            ],
            "Resource": "arn:aws:kms:ap-northeast-1:123456789012:key/15dfcb2a-6625-4f70-b9a6-edcec05d6f03",
            "Effect": "Allow",
            "Sid": "SamplePolicy"
        },

arn:aws:kms:ap-northeast-1:350863595295:key/d080fc59-17e7-48db-9e76-1c81d820b958